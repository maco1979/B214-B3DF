#!/usr/bin/env python3
"""AI PTZäº‘å°è½¬åŠ¨æ£€æµ‹è„šæœ¬"""

import asyncio
import time
import cv2
from backend.src.core.services.camera_controller import CameraController
from backend.src.core.services.ptz_camera_controller import PTZCameraController, PTZProtocol, PTZAction

class AIPtzDetection:
    """AI PTZäº‘å°è½¬åŠ¨æ£€æµ‹ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ£€æµ‹ç³»ç»Ÿ"""
        self.monitor_camera = CameraController()  # ç›‘æ§æ‘„åƒå¤´ï¼ˆç¬¬äºŒä¸ªæ‘„åƒå¤´ï¼‰
        self.ptz_camera = CameraController()      # PTZæ‘„åƒå¤´ï¼ˆç¬¬ä¸€ä¸ªæ‘„åƒå¤´ï¼‰
        self.ptz_controller = None                # PTZæ§åˆ¶å™¨
        self.detection_results = []               # æ£€æµ‹ç»“æœ
        self.is_monitoring = False                # ç›‘æ§çŠ¶æ€
    
    def list_available_cameras(self):
        """åˆ—å‡ºå¯ç”¨æ‘„åƒå¤´"""
        print("=== æ£€æµ‹å¯ç”¨æ‘„åƒå¤´ ===")
        result = self.monitor_camera.list_cameras(max_index=3)
        
        if result["success"]:
            print(f"æ£€æµ‹åˆ° {result['available_count']} ä¸ªå¯ç”¨æ‘„åƒå¤´:")
            for i, cam in enumerate(result["cameras"]):
                print(f"  {i+1}. ç´¢å¼•: {cam['index']}, ç±»å‹: {cam['type']}, åˆ†è¾¨ç‡: {cam['width']}x{cam['height']}")
        
        return result["cameras"]
    
    def setup_cameras(self, monitor_index=1, ptz_index=0):
        """è®¾ç½®ç›‘æ§æ‘„åƒå¤´å’ŒPTZæ‘„åƒå¤´"""
        print(f"\n=== è®¾ç½®æ‘„åƒå¤´ ===")
        print(f"1. æ‰“å¼€ç›‘æ§æ‘„åƒå¤´ï¼ˆç´¢å¼•: {monitor_index}ï¼‰...")
        
        # æ‰“å¼€ç›‘æ§æ‘„åƒå¤´
        monitor_result = self.monitor_camera.open_camera(monitor_index)
        if monitor_result["success"]:
            print(f"   âœ… ç›‘æ§æ‘„åƒå¤´æ‰“å¼€æˆåŠŸ: {monitor_result['message']}")
        else:
            print(f"   âŒ ç›‘æ§æ‘„åƒå¤´æ‰“å¼€å¤±è´¥: {monitor_result['message']}")
            return False
        
        # æ‰“å¼€PTZæ‘„åƒå¤´
        print(f"2. æ‰“å¼€PTZæ‘„åƒå¤´ï¼ˆç´¢å¼•: {ptz_index}ï¼‰...")
        ptz_result = self.ptz_camera.open_camera(ptz_index)
        if ptz_result["success"]:
            print(f"   âœ… PTZæ‘„åƒå¤´æ‰“å¼€æˆåŠŸ: {ptz_result['message']}")
        else:
            print(f"   âŒ PTZæ‘„åƒå¤´æ‰“å¼€å¤±è´¥: {ptz_result['message']}")
            return False
        
        # åˆå§‹åŒ–PTZæ§åˆ¶å™¨
        print("3. åˆå§‹åŒ–PTZæ§åˆ¶å™¨...")
        self.ptz_controller = PTZCameraController(
            protocol=PTZProtocol.HTTP_API,
            connection_type="http",
            base_url="http://192.168.1.64",  # è¯·æ›¿æ¢ä¸ºçœŸå®PTZæ‘„åƒå¤´IP
            username="admin",
            password="admin"
        )
        
        asyncio.run(self.ptz_controller.connect())
        print(f"   âœ… PTZæ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
        
        return True
    
    def start_visual_monitoring(self):
        """å¯åŠ¨è§†è§‰ç›‘æ§"""
        print("\n=== å¯åŠ¨è§†è§‰ç›‘æ§ ===")
        
        # å¯åŠ¨è§†è§‰è¯†åˆ«
        recognition_result = self.monitor_camera.start_visual_recognition(model_type='haar')
        if recognition_result["success"]:
            print(f"   âœ… è§†è§‰è¯†åˆ«å¯åŠ¨æˆåŠŸ: {recognition_result['message']}")
        else:
            print(f"   âŒ è§†è§‰è¯†åˆ«å¯åŠ¨å¤±è´¥: {recognition_result['message']}")
            return False
        
        # å¯åŠ¨è§†è§‰è·Ÿè¸ª
        tracking_result = self.monitor_camera.start_visual_tracking(tracker_type='MIL')
        if tracking_result["success"]:
            print(f"   âœ… è§†è§‰è·Ÿè¸ªå¯åŠ¨æˆåŠŸ: {tracking_result['message']}")
        else:
            print(f"   âŒ è§†è§‰è·Ÿè¸ªå¯åŠ¨å¤±è´¥: {tracking_result['message']}")
            return False
        
        self.is_monitoring = True
        return True
    
    def capture_reference_frame(self):
        """æ•è·å‚è€ƒå¸§"""
        print("\n=== æ•è·å‚è€ƒå¸§ ===")
        
        # ç­‰å¾…æ‘„åƒå¤´ç¨³å®š
        time.sleep(1)
        
        # æ•è·å‚è€ƒå¸§
        reference_frame = self.monitor_camera.take_photo()
        if reference_frame is not None:
            print(f"   âœ… å‚è€ƒå¸§æ•è·æˆåŠŸï¼Œåˆ†è¾¨ç‡: {reference_frame.shape[1]}x{reference_frame.shape[0]}")
            cv2.imwrite("reference_frame.jpg", reference_frame)
            print("   ğŸ“¸ å‚è€ƒå¸§å·²ä¿å­˜ä¸º reference_frame.jpg")
            return reference_frame
        else:
            print(f"   âŒ å‚è€ƒå¸§æ•è·å¤±è´¥")
            return None
    
    async def execute_ptz_action(self, action, duration=3, speed=100):
        """æ‰§è¡ŒPTZåŠ¨ä½œ"""
        print(f"\n=== æ‰§è¡ŒPTZåŠ¨ä½œ: {action.value} ===")
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # æ‰§è¡ŒPTZåŠ¨ä½œ
        if action == PTZAction.PAN_LEFT:
            result = await self.ptz_controller.execute_action(action, speed)
        elif action == PTZAction.PAN_RIGHT:
            result = await self.ptz_controller.execute_action(action, speed)
        elif action == PTZAction.TILT_UP:
            result = await self.ptz_controller.execute_action(action, speed)
        elif action == PTZAction.TILT_DOWN:
            result = await self.ptz_controller.execute_action(action, speed)
        else:
            result = {"success": False, "message": f"ä¸æ”¯æŒçš„åŠ¨ä½œ: {action.value}"}
        
        if result["success"]:
            print(f"   âœ… {action.value} åŠ¨ä½œæ‰§è¡ŒæˆåŠŸ")
        else:
            print(f"   âŒ {action.value} åŠ¨ä½œæ‰§è¡Œå¤±è´¥: {result['message']}")
            return False
        
        # ç­‰å¾…åŠ¨ä½œå®Œæˆ
        print(f"   â±ï¸  åŠ¨ä½œæŒç»­ {duration} ç§’...")
        await asyncio.sleep(duration)
        
        # åœæ­¢PTZåŠ¨ä½œ
        stop_result = await self.ptz_controller.execute_action(PTZAction.STOP, 0)
        if stop_result["success"]:
            print(f"   âœ… åŠ¨ä½œåœæ­¢æˆåŠŸ")
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        
        return True
    
    def detect_movement(self, reference_frame):
        """æ£€æµ‹PTZæ‘„åƒå¤´çš„ç§»åŠ¨"""
        print("\n=== æ£€æµ‹PTZç§»åŠ¨ ===")
        
        # æ•è·å½“å‰å¸§
        current_frame = self.monitor_camera.take_photo()
        if current_frame is None:
            print(f"   âŒ å½“å‰å¸§æ•è·å¤±è´¥")
            return False
        
        # ä¿å­˜å½“å‰å¸§
        cv2.imwrite("current_frame.jpg", current_frame)
        print("   ğŸ“¸ å½“å‰å¸§å·²ä¿å­˜ä¸º current_frame.jpg")
        
        # ä½¿ç”¨ç®€å•çš„å·®å¼‚æ£€æµ‹
        reference_gray = cv2.cvtColor(reference_frame, cv2.COLOR_BGR2GRAY)
        current_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)
        
        # è°ƒæ•´å¤§å°ä»¥æé«˜æ€§èƒ½
        ref_resized = cv2.resize(reference_gray, (320, 240))
        curr_resized = cv2.resize(current_gray, (320, 240))
        
        # è®¡ç®—å·®å¼‚
        diff = cv2.absdiff(ref_resized, curr_resized)
        
        # é˜ˆå€¼åŒ–å·®å¼‚å›¾åƒ
        _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)
        
        # è®¡ç®—å·®å¼‚åƒç´ æ•°é‡
        diff_pixels = cv2.countNonZero(thresh)
        total_pixels = ref_resized.shape[0] * ref_resized.shape[1]
        diff_percentage = (diff_pixels / total_pixels) * 100
        
        # ä¿å­˜å·®å¼‚å›¾åƒ
        cv2.imwrite("diff_image.jpg", thresh)
        
        print(f"   ğŸ“Š å·®å¼‚æ£€æµ‹ç»“æœ:")
        print(f"      - å·®å¼‚åƒç´ æ•°: {diff_pixels}")
        print(f"      - æ€»åƒç´ æ•°: {total_pixels}")
        print(f"      - å·®å¼‚ç™¾åˆ†æ¯”: {diff_percentage:.2f}%")
        
        # åˆ¤å®šæ˜¯å¦æœ‰æ˜æ˜¾ç§»åŠ¨ï¼ˆå·®å¼‚è¶…è¿‡5%ï¼‰
        is_moved = diff_percentage > 5.0
        
        if is_moved:
            print(f"   âœ… æ£€æµ‹åˆ°æ˜æ˜¾ç§»åŠ¨ï¼")
        else:
            print(f"   âš ï¸  æœªæ£€æµ‹åˆ°æ˜æ˜¾ç§»åŠ¨")
        
        # ä¿å­˜æ£€æµ‹ç»“æœ
        self.detection_results.append({
            "timestamp": time.time(),
            "diff_percentage": diff_percentage,
            "is_moved": is_moved,
            "diff_pixels": diff_pixels
        })
        
        return is_moved
    
    def run_detection_sequence(self):
        """è¿è¡Œå®Œæ•´æ£€æµ‹åºåˆ—"""
        print("\n" + "="*50)
        print("=== AI PTZäº‘å°è½¬åŠ¨æ£€æµ‹ç³»ç»Ÿ ===")
        print("="*50)
        
        # 1. åˆ—å‡ºå¯ç”¨æ‘„åƒå¤´
        available_cameras = self.list_available_cameras()
        
        if len(available_cameras) < 2:
            print("\nâŒ é”™è¯¯ï¼šç³»ç»Ÿéœ€è¦è‡³å°‘2ä¸ªæ‘„åƒå¤´ï¼Œ1ä¸ªç”¨äºç›‘æ§ï¼Œ1ä¸ªç”¨äºPTZæµ‹è¯•")
            return False
        
        # 2. è®¾ç½®æ‘„åƒå¤´
        if not self.setup_cameras(monitor_index=1, ptz_index=0):
            return False
        
        # 3. å¯åŠ¨è§†è§‰ç›‘æ§
        if not self.start_visual_monitoring():
            return False
        
        # 4. æ•è·å‚è€ƒå¸§
        reference_frame = self.capture_reference_frame()
        if reference_frame is None:
            return False
        
        # 5. æ‰§è¡ŒPTZåŠ¨ä½œå¹¶æ£€æµ‹
        asyncio.run(self._execute_detection_async(reference_frame))
        
        # 6. ç”Ÿæˆæ£€æµ‹æŠ¥å‘Š
        self.generate_report()
        
        # 7. æ¸…ç†èµ„æº
        self.cleanup()
        
        return True
    
    async def _execute_detection_async(self, reference_frame):
        """å¼‚æ­¥æ‰§è¡Œæ£€æµ‹"""
        # æ‰§è¡Œå¤šä¸ªPTZåŠ¨ä½œå¹¶æ£€æµ‹
        actions = [
            PTZAction.PAN_LEFT,
            PTZAction.PAN_RIGHT,
            PTZAction.TILT_UP,
            PTZAction.TILT_DOWN
        ]
        
        for action in actions:
            # æ‰§è¡ŒPTZåŠ¨ä½œ
            await self.execute_ptz_action(action, duration=2, speed=100)
            
            # æ£€æµ‹ç§»åŠ¨
            self.detect_movement(reference_frame)
            
            # ç­‰å¾…1ç§’
            await asyncio.sleep(1)
        
        # æ‰§è¡Œå¤§è§’åº¦ç§»åŠ¨æµ‹è¯•ï¼ˆ>100Â°ï¼‰
        print("\n=== æ‰§è¡Œå¤§è§’åº¦ç§»åŠ¨æµ‹è¯•ï¼ˆ>100Â°ï¼‰===")
        
        # è·å–åˆå§‹ä½ç½®
        initial_state = self.ptz_controller.get_status()
        initial_pan = initial_state["position"]["pan"]
        
        # æ‰§è¡Œ180Â°æ—‹è½¬
        result = await self.ptz_controller.move_to_position(pan=initial_pan + 180, tilt=initial_state["position"]["tilt"], speed=100)
        if result["success"]:
            print(f"   âœ… 180Â°æ—‹è½¬æ‰§è¡ŒæˆåŠŸ")
            # æ£€æµ‹å¤§è§’åº¦ç§»åŠ¨
            self.detect_movement(reference_frame)
        
        # å¤ä½åˆ°åˆå§‹ä½ç½®
        await self.ptz_controller.move_to_position(pan=initial_pan, tilt=initial_state["position"]["tilt"], speed=100)
    
    def generate_report(self):
        """ç”Ÿæˆæ£€æµ‹æŠ¥å‘Š"""
        print("\n" + "="*50)
        print("=== AI PTZäº‘å°è½¬åŠ¨æ£€æµ‹æŠ¥å‘Š ===")
        print("="*50)
        
        # ç»Ÿè®¡æ£€æµ‹ç»“æœ
        total_tests = len(self.detection_results)
        moved_tests = sum(1 for r in self.detection_results if r["is_moved"])
        accuracy = (moved_tests / total_tests) * 100 if total_tests > 0 else 0
        
        print(f"\nğŸ“‹ æ£€æµ‹ç»“æœç»Ÿè®¡:")
        print(f"   - æ€»æµ‹è¯•æ¬¡æ•°: {total_tests}")
        print(f"   - æ£€æµ‹åˆ°ç§»åŠ¨æ¬¡æ•°: {moved_tests}")
        print(f"   - æ£€æµ‹å‡†ç¡®ç‡: {accuracy:.2f}%")
        
        print(f"\nğŸ“Š è¯¦ç»†æ£€æµ‹ç»“æœ:")
        for i, result in enumerate(self.detection_results):
            status = "âœ… ç§»åŠ¨" if result["is_moved"] else "âš ï¸  æœªç§»åŠ¨"
            print(f"   {i+1}. å·®å¼‚: {result['diff_percentage']:.2f}% {status}")
        
        print(f"\nğŸ” åˆ†æç»“è®º:")
        if moved_tests > 0:
            print(f"   âœ… æˆåŠŸï¼AIå¯ä»¥æ£€æµ‹åˆ°PTZæ‘„åƒå¤´çš„è½¬åŠ¨")
            print(f"   ğŸ¯ ç³»ç»Ÿèƒ½å¤Ÿé€šè¿‡ç¬¬äºŒä¸ªæ‘„åƒå¤´ç›‘æ§ç¬¬ä¸€ä¸ªæ‘„åƒå¤´çš„PTZåŠ¨ä½œ")
        else:
            print(f"   âš ï¸  è­¦å‘Šï¼šæœªæ£€æµ‹åˆ°PTZæ‘„åƒå¤´çš„è½¬åŠ¨")
            print(f"   ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥PTZæ‘„åƒå¤´æ˜¯å¦æ”¯æŒPTZæ§åˆ¶ï¼Œæˆ–è€…è°ƒæ•´æ‘„åƒå¤´ä½ç½®")
        
        # ä¿å­˜æŠ¥å‘Š
        with open("ptz_detection_report.txt", "w") as f:
            f.write("AI PTZäº‘å°è½¬åŠ¨æ£€æµ‹æŠ¥å‘Š\n")
            f.write("="*50 + "\n")
            f.write(f"æ£€æµ‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ€»æµ‹è¯•æ¬¡æ•°: {total_tests}\n")
            f.write(f"æ£€æµ‹åˆ°ç§»åŠ¨æ¬¡æ•°: {moved_tests}\n")
            f.write(f"æ£€æµ‹å‡†ç¡®ç‡: {accuracy:.2f}%\n\n")
            f.write("è¯¦ç»†ç»“æœ:\n")
            for i, result in enumerate(self.detection_results):
                status = "ç§»åŠ¨" if result["is_moved"] else "æœªç§»åŠ¨"
                f.write(f"{i+1}. å·®å¼‚: {result['diff_percentage']:.2f}% - {status}\n")
        
        print(f"\nğŸ“„ æ£€æµ‹æŠ¥å‘Šå·²ä¿å­˜ä¸º ptz_detection_report.txt")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("\n=== æ¸…ç†èµ„æº ===")
        
        # å…³é—­ç›‘æ§æ‘„åƒå¤´
        self.monitor_camera.close_camera()
        print(f"   âœ… ç›‘æ§æ‘„åƒå¤´å·²å…³é—­")
        
        # å…³é—­PTZæ‘„åƒå¤´
        self.ptz_camera.close_camera()
        print(f"   âœ… PTZæ‘„åƒå¤´å·²å…³é—­")
        
        # æ–­å¼€PTZæ§åˆ¶å™¨
        if self.ptz_controller:
            asyncio.run(self.ptz_controller.disconnect())
            print(f"   âœ… PTZæ§åˆ¶å™¨å·²æ–­å¼€")
        
        print(f"   âœ… æ‰€æœ‰èµ„æºå·²æ¸…ç†")
    
    def get_status(self):
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return {
            "is_monitoring": self.is_monitoring,
            "monitor_camera_open": self.monitor_camera.is_camera_open(),
            "ptz_camera_open": self.ptz_camera.is_camera_open(),
            "detection_results_count": len(self.detection_results)
        }

if __name__ == "__main__":
    # åˆ›å»ºæ£€æµ‹ç³»ç»Ÿ
    detector = AIPtzDetection()
    
    try:
        # è¿è¡Œæ£€æµ‹åºåˆ—
        detector.run_detection_sequence()
    except KeyboardInterrupt:
        print("\n\nğŸ”´ æ£€æµ‹è¢«ç”¨æˆ·ä¸­æ–­")
        detector.cleanup()
    except Exception as e:
        print(f"\n\nâŒ æ£€æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        detector.cleanup()
    finally:
        print("\nğŸ‰ AI PTZäº‘å°è½¬åŠ¨æ£€æµ‹å®Œæˆ")