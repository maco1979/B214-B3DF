#!/usr/bin/env python3
"""
é«˜çº§è”é‚¦å­¦ä¹ æ¨¡å—æµ‹è¯•
éªŒè¯æ”¹è¿›åçš„æœ¬åœ°è®­ç»ƒåŠŸèƒ½æ›´åŠ çœŸå®
"""

import sys
import os
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'backend'))

from backend.src.federated.federated_learning import FederatedLearningServer, FederatedLearningClient

def test_advanced_local_training():
    print("ğŸ” æµ‹è¯•æ”¹è¿›åçš„æœ¬åœ°è®­ç»ƒåŠŸèƒ½...")
    
    # åˆ›å»ºè”é‚¦å­¦ä¹ æœåŠ¡å™¨
    model_architecture = {
        "name": "test_model",
        "layers": [
            {"type": "dense", "input_units": 10, "units": 64, "activation": "relu"},
            {"type": "dense", "units": 32, "activation": "relu"},
            {"type": "dense", "units": 5, "activation": "softmax"}
        ]
    }
    
    print("âœ… åˆ›å»ºè”é‚¦å­¦ä¹ æœåŠ¡å™¨")
    server = FederatedLearningServer(model_architecture)
    
    # æ£€æŸ¥æ¨¡å‹å‚æ•°
    print(f"âœ… æ¨¡å‹å‚æ•°å±‚æ•°é‡: {server.global_model['metadata']['parameter_count']}")
    
    # åˆ›å»ºå…·æœ‰ä¸åŒæ•°æ®ç‰¹å¾çš„å®¢æˆ·ç«¯
    print("\nğŸ“‹ åˆ›å»ºå…·æœ‰ä¸åŒæ•°æ®ç‰¹å¾çš„å®¢æˆ·ç«¯...")
    
    # å®¢æˆ·ç«¯1: è¾ƒå¤§æ•°æ®é›†
    client1_data = np.random.random((1000, 10))  # 1000ä¸ªæ ·æœ¬ï¼Œ10ä¸ªç‰¹å¾
    client1 = FederatedLearningClient("client_1", client1_data)
    client1.initialize_with_global_model(server._prepare_client_model())
    
    # å®¢æˆ·ç«¯2: è¾ƒå°æ•°æ®é›†
    client2_data = np.random.random((100, 10))   # 100ä¸ªæ ·æœ¬ï¼Œ10ä¸ªç‰¹å¾
    client2 = FederatedLearningClient("client_2", client2_data)
    client2.initialize_with_global_model(server._prepare_client_model())
    
    print("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
    print(f"  - å®¢æˆ·ç«¯1æ•°æ®å¤§å°: {len(client1_data)}")
    print(f"  - å®¢æˆ·ç«¯2æ•°æ®å¤§å°: {len(client2_data)}")
    
    # æ‰§è¡Œæœ¬åœ°è®­ç»ƒ
    print("\nğŸ¤– æ‰§è¡Œæ”¹è¿›åçš„æœ¬åœ°è®­ç»ƒ...")
    
    training_config = {
        "learning_rate": 0.01,
        "epochs": 3,
        "batch_size": 32
    }
    
    # å®¢æˆ·ç«¯1è®­ç»ƒ
    print("  - å®¢æˆ·ç«¯1è®­ç»ƒä¸­...")
    update1 = client1.local_training(training_config)
    print(f"  âœ… å®¢æˆ·ç«¯1è®­ç»ƒå®Œæˆï¼Œæ›´æ–°å‚æ•°æ•°é‡: {len(update1['parameters'])}")
    print(f"  âœ… å®¢æˆ·ç«¯1è®­ç»ƒæ—¶é—´: {update1['training_time']:.4f}s")
    
    # å®¢æˆ·ç«¯2è®­ç»ƒ
    print("  - å®¢æˆ·ç«¯2è®­ç»ƒä¸­...")
    update2 = client2.local_training(training_config)
    print(f"  âœ… å®¢æˆ·ç«¯2è®­ç»ƒå®Œæˆï¼Œæ›´æ–°å‚æ•°æ•°é‡: {len(update2['parameters'])}")
    print(f"  âœ… å®¢æˆ·ç«¯2è®­ç»ƒæ—¶é—´: {update2['training_time']:.4f}s")
    
    # éªŒè¯æ›´æ–°æ˜¯å¦åŸºäºæ•°æ®å¤§å°æœ‰æ‰€ä¸åŒ
    print("\nğŸ“Š éªŒè¯è®­ç»ƒç»“æœå·®å¼‚...")
    
    # æ£€æŸ¥å‚æ•°æ›´æ–°æ˜¯å¦åˆç†
    for key in update1['parameters'].keys():
        update1_norm = np.linalg.norm(update1['parameters'][key])
        update2_norm = np.linalg.norm(update2['parameters'][key])
        print(f"  - å‚æ•° {key}: å®¢æˆ·ç«¯1æ›´æ–°èŒƒæ•°={update1_norm:.6f}, å®¢æˆ·ç«¯2æ›´æ–°èŒƒæ•°={update2_norm:.6f}")
    
    # æ³¨å†Œå®¢æˆ·ç«¯åˆ°æœåŠ¡å™¨
    print("\nğŸ“‹ æ³¨å†Œå®¢æˆ·ç«¯åˆ°æœåŠ¡å™¨...")
    server.register_client("client_1", {"data_size": len(client1_data)})
    server.register_client("client_2", {"data_size": len(client2_data)})
    
    # å¼€å§‹è®­ç»ƒè½®æ¬¡
    print("\nğŸ”„ å¼€å§‹è”é‚¦å­¦ä¹ è½®æ¬¡...")
    round_config = {
        "client_fraction": 1.0,
        "learning_rate": 0.01,
        "epochs": 1
    }
    
    round_info = server.start_training_round(round_config)
    print(f"âœ… è½®æ¬¡ {round_info['round_id']} å¯åŠ¨æˆåŠŸ")
    
    # æäº¤æ›´æ–°
    print("\nğŸ“¤ æäº¤å®¢æˆ·ç«¯æ›´æ–°...")
    server.receive_client_update("client_1", round_info['round_id'], update1)
    server.receive_client_update("client_2", round_info['round_id'], update2)
    print("âœ… å®¢æˆ·ç«¯æ›´æ–°æäº¤æˆåŠŸ")
    
    # èšåˆæ›´æ–°
    print("\nğŸ§® èšåˆæ›´æ–°...")
    success = server.aggregate_updates(round_info['round_id'])
    if success:
        print("âœ… æ›´æ–°èšåˆæˆåŠŸ")
    else:
        print("âŒ æ›´æ–°èšåˆå¤±è´¥")
        return False
    
    # éªŒè¯èšåˆåçš„æ¨¡å‹å‚æ•°
    print("\nğŸ” éªŒè¯èšåˆåæ¨¡å‹...")
    final_param_count = len(server.global_model['parameters'])
    print(f"âœ… èšåˆåæ¨¡å‹å‚æ•°æ•°é‡: {final_param_count}")
    
    # æ£€æŸ¥èšåˆæ˜¯å¦æœ‰æ•ˆ
    if server.rounds_completed > 0:
        print(f"âœ… è½®æ¬¡å®Œæˆæ•°é‡: {server.rounds_completed}")
        print("âœ… è”é‚¦å­¦ä¹ æµç¨‹å®Œæ•´")
    else:
        print("âŒ è½®æ¬¡æœªå®Œæˆ")
        return False
    
    print("\nğŸ‰ é«˜çº§è”é‚¦å­¦ä¹ æµ‹è¯•å®Œæˆï¼æœ¬åœ°è®­ç»ƒåŠŸèƒ½æ›´åŠ çœŸå®ã€‚")
    return True

def test_training_config_impact():
    """æµ‹è¯•ä¸åŒè®­ç»ƒé…ç½®å¯¹æœ¬åœ°è®­ç»ƒçš„å½±å“"""
    print("\nğŸ§ª æµ‹è¯•ä¸åŒè®­ç»ƒé…ç½®çš„å½±å“...")
    
    # åˆ›å»ºæ¨¡å‹å’Œå®¢æˆ·ç«¯
    model_architecture = {
        "name": "config_test_model",
        "layers": [{"type": "dense", "input_units": 5, "units": 10, "activation": "relu"}]
    }
    
    server = FederatedLearningServer(model_architecture)
    client_data = np.random.random((500, 5))
    
    # æµ‹è¯•ä¸åŒçš„å­¦ä¹ ç‡
    configs = [
        {"learning_rate": 0.001, "epochs": 1, "batch_size": 32, "name": "ä½å­¦ä¹ ç‡"},
        {"learning_rate": 0.01, "epochs": 1, "batch_size": 32, "name": "ä¸­å­¦ä¹ ç‡"},
        {"learning_rate": 0.1, "epochs": 1, "batch_size": 32, "name": "é«˜å­¦ä¹ ç‡"},
        {"learning_rate": 0.01, "epochs": 1, "batch_size": 32, "name": "å•è½®è®­ç»ƒ"},
        {"learning_rate": 0.01, "epochs": 5, "batch_size": 32, "name": "å¤šè½®è®­ç»ƒ"}
    ]
    
    client_updates = []
    
    for i, config in enumerate(configs):
        print(f"  - {config['name']}é…ç½®è®­ç»ƒ...")
        client = FederatedLearningClient(f"test_client_{i}", client_data)
        client.initialize_with_global_model(server._prepare_client_model())
        
        update = client.local_training(config)
        update_norm = sum(np.linalg.norm(param) for param in update['parameters'].values())
        client_updates.append((config['name'], update_norm, update['training_time']))
        print(f"    âœ… æ›´æ–°èŒƒæ•°: {update_norm:.6f}, è®­ç»ƒæ—¶é—´: {update['training_time']:.4f}s")
    
    print("\nğŸ“ˆ é…ç½®å½±å“åˆ†æ:")
    for name, norm, time in client_updates:
        print(f"  - {name}: æ›´æ–°èŒƒæ•°={norm:.6f}, æ—¶é—´={time:.4f}s")
    
    return True

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹é«˜çº§è”é‚¦å­¦ä¹ æµ‹è¯•...")
    
    success1 = test_advanced_local_training()
    success2 = test_training_config_impact()
    
    if success1 and success2:
        print("\nâœ… æ‰€æœ‰é«˜çº§æµ‹è¯•é€šè¿‡ï¼æœ¬åœ°è®­ç»ƒåŠŸèƒ½æ›´åŠ çœŸå®å’Œæœ‰æ•ˆã€‚")
        sys.exit(0)
    else:
        print("\nâŒ é«˜çº§æµ‹è¯•å¤±è´¥ï¼")
        sys.exit(1)