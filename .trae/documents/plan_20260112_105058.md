# 语音处理架构设计与实现方案

## 一、当前项目语音处理现状

当前项目在 `AIControl.tsx` 中实现了一个简单的语音控制功能：
- 使用浏览器内置的 `SpeechRecognition API`
- 仅支持简单的指令识别（如"开启主控"）
- 没有自然语言处理（NLP）和语音合成（TTS）
- 没有边缘与云端协同

## 二、完整语音处理架构设计

### 1. 架构组件

| 组件 | 功能 | 技术选型 | 位置 |
|------|------|----------|------|
| 语音识别 (ASR) | 将语音转换为文本 | 浏览器内置 SpeechRecognition API + 可选的云端 ASR 服务 | 前端/边缘 |
| 自然语言处理 (NLP) | 解析文本意图，理解用户需求 | 自定义 NLP 引擎 + 可选的云端 NLP 服务 | 前端/后端 |
| 语音合成 (TTS) | 将系统响应转换为语音 | 浏览器内置 SpeechSynthesis API + 可选的云端 TTS 服务 | 前端/边缘 |
| 边缘与云端协同 | 本地处理与云端处理的协同 | 本地优先，复杂任务云端处理 | 前端+后端 |

### 2. 技术实现方案

#### 2.1 语音识别 (ASR)
- **前端实现**：使用浏览器内置的 `SpeechRecognition API`
- **功能增强**：
  - 支持实时流式转写
  - 支持中文普通话和多种方言
  - 添加噪音抑制和语音增强
  - 实现唤醒词功能

#### 2.2 自然语言处理 (NLP)
- **核心功能**：
  - 语义理解
  - 意图识别
  - 上下文管理
  - 实体提取
- **实现方式**：
  - 前端：简单意图本地处理
  - 后端：复杂意图云端处理
  - 支持多轮对话

#### 2.3 语音合成 (TTS)
- **前端实现**：使用浏览器内置的 `SpeechSynthesis API`
- **功能增强**：
  - 支持多种语音和语速
  - 实现情感合成
  - 支持自定义语音风格

#### 2.4 边缘与云端协同
- **本地优先原则**：简单指令本地处理，复杂指令云端处理
- **隐私保护**：本地处理不发送用户语音数据到云端
- **容错机制**：本地处理失败时自动切换到云端处理

## 三、实现步骤

### 1. 前端语音处理模块

#### 1.1 创建语音处理服务
```typescript
// src/services/voiceService.ts
class VoiceService {
  private recognition: any;
  private synthesis: SpeechSynthesis;
  private isListening: boolean;
  private callbacks: {
    onResult: (text: string) => void;
    onError: (error: string) => void;
    onStatusChange: (isListening: boolean) => void;
  };

  constructor() {
    this.synthesis = window.speechSynthesis;
    this.isListening = false;
    this.callbacks = {
      onResult: () => {},
      onError: () => {},
      onStatusChange: () => {}
    };
    this.initRecognition();
  }

  private initRecognition() {
    // 初始化 SpeechRecognition
  }

  startListening() {
    // 开始监听语音
  }

  stopListening() {
    // 停止监听语音
  }

  speak(text: string, options?: { voice?: SpeechSynthesisVoice; rate?: number; pitch?: number }) {
    // 语音合成
  }

  // 其他方法...
}
```

#### 1.2 创建 NLP 处理模块
```typescript
// src/services/nlpService.ts
class NLPService {
  private intentRules: {
    pattern: RegExp;
    intent: string;
    action: (entities: any) => void;
  }[];

  constructor() {
    this.intentRules = [
      {
        pattern: /打开主控|开启主控/g,
        intent: "TOGGLE_MASTER_CONTROL",
        action: () => {
          // 执行开启主控操作
        }
      },
      {
        pattern: /打开摄像头(\d+)?/g,
        intent: "OPEN_CAMERA",
        action: (entities: { cameraIndex?: number }) => {
          // 执行打开摄像头操作
        }
      },
      // 更多意图规则...
    ];
  }

  processText(text: string) {
    // 解析文本，识别意图和实体
    // 执行对应的操作
  }

  // 其他 NLP 功能...
}
```

#### 1.3 集成到 AIControl 组件
```typescript
// src/pages/AIControl.tsx
const AIControl = () => {
  // ... 现有代码 ...

  // 初始化语音服务
  const voiceService = useRef(new VoiceService());
  const nlpService = useRef(new NLPService());

  // 语音控制逻辑
  const initVoiceControl = () => {
    voiceService.current.onResult = (text: string) => {
      setLastCommand(text);
      // 处理语音识别结果
      nlpService.current.processText(text);
    };

    voiceService.current.onError = (error: string) => {
      console.error("语音识别错误:", error);
    };
  };

  // ... 其他代码 ...

  return (
    // ... 现有代码 ...
  );
};
```

### 2. 后端语音处理模块

#### 2.1 创建语音处理 API
```python
# src/api/routes/voice.py
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from src.core.response import success_response, error_response

router = APIRouter(prefix="/voice", tags=["voice"])

class VoiceRequest(BaseModel):
    text: str
    context: dict = {}

@router.post("/process", response_model=ApiResponse)
async def process_voice_request(request: VoiceRequest):
    """处理语音请求，进行复杂的自然语言处理"""
    try:
        # 调用 NLP 服务处理请求
        result = await nlp_service.process_text(request.text, request.context)
        return success_response(data=result, message="语音请求处理成功")
    except Exception as e:
        return error_response(code=500, message=f"语音请求处理失败: {str(e)}")
```

#### 2.2 创建 NLP 服务
```python
# src/core/services/nlp_service.py
class NLPService:
    async def process_text(self, text: str, context: dict = {}):
        """处理文本，识别意图和实体"""
        # 实现复杂的自然语言处理逻辑
        # 支持上下文管理和多轮对话
        pass
```

### 3. 边缘与云端协同

#### 3.1 协同策略
```typescript
// src/services/voiceCloudService.ts
class VoiceCloudService {
  private isOnline: boolean;

  constructor() {
    this.isOnline = navigator.onLine;
    window.addEventListener("online", () => { this.isOnline = true; });
    window.addEventListener("offline", () => { this.isOnline = false; });
  }

  async processComplexRequest(request: any) {
    if (!this.isOnline) {
      throw new Error("网络连接不可用");
    }

    // 发送请求到云端处理
    const response = await fetch("/api/voice/process", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(request)
    });

    return await response.json();
  }
}
```

## 三、实现步骤

1. **前端语音服务实现**：
   - 创建 `voiceService.ts`，实现语音识别和语音合成
   - 创建 `nlpService.ts`，实现基础的自然语言处理
   - 集成到 `AIControl.tsx` 组件

2. **后端语音处理 API**：
   - 创建 `voice.py` API 路由
   - 创建 `nlp_service.py` 服务
   - 实现复杂的自然语言处理功能

3. **边缘与云端协同**：
   - 创建 `voiceCloudService.ts`，实现本地和云端处理的协同
   - 实现本地优先，复杂任务云端处理的策略

4. **功能增强**：
   - 添加唤醒词功能
   - 支持多种方言和语言
   - 实现情感合成
   - 添加噪音抑制和语音增强

## 四、预期效果

1. **完整的语音交互**：支持语音输入、意图理解和语音输出
2. **复杂指令处理**：能够理解复杂的语音指令，如"打开客厅的灯并把空调调到26度"
3. **边缘与云端协同**：本地处理简单任务，云端处理复杂任务
4. **良好的用户体验**：实时响应，自然的语音交互
5. **隐私保护**：敏感数据本地处理，不发送到云端

## 五、技术栈

| 技术 | 用途 |
|------|------|
| React + TypeScript | 前端开发 |
| FastAPI | 后端 API 开发 |
| 浏览器内置 SpeechRecognition API | 前端语音识别 |
| 浏览器内置 SpeechSynthesis API | 前端语音合成 |
| 自定义 NLP 引擎 | 自然语言处理 |
| 可选的云端 ASR/TTS/NLP 服务 | 增强的语音处理能力 |