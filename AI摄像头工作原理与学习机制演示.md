# ğŸ¥ AIæ‘„åƒå¤´å·¥ä½œåŸç†ä¸å­¦ä¹ æœºåˆ¶å®Œæ•´æ¼”ç¤º

> **æ¼”ç¤ºæ—¶é—´ï¼š** 2025-12-31  
> **ç³»ç»Ÿç‰ˆæœ¬ï¼š** 1.5  
> **æ¼”ç¤ºç›®æ ‡ï¼š** å±•ç¤ºAIæ‘„åƒå¤´è½¬åŠ¨ã€å·¥ä½œåŸç†ã€æ•°æ®æµè½¬ã€AIå­¦ä¹ è¿‡ç¨‹åŠè¿›åº¦ç›‘æ§

---

## ğŸ“‹ ç›®å½•

1. [AIæ‘„åƒå¤´è½¬åŠ¨ä¸è·Ÿè¸ªæœºåˆ¶](#1-aiæ‘„åƒå¤´è½¬åŠ¨ä¸è·Ÿè¸ªæœºåˆ¶)
2. [AIæ‘„åƒå¤´å·¥ä½œæµç¨‹](#2-aiæ‘„åƒå¤´å·¥ä½œæµç¨‹)
3. [ä»ªè¡¨ç›˜æ•°æ®è·å–æœºåˆ¶](#3-ä»ªè¡¨ç›˜æ•°æ®è·å–æœºåˆ¶)
4. [AIå­¦ä¹ æœºåˆ¶è¯¦è§£](#4-aiå­¦ä¹ æœºåˆ¶è¯¦è§£)
5. [AIå­¦ä¹ è¿›åº¦æ£€æµ‹æ–¹æ³•](#5-aiå­¦ä¹ è¿›åº¦æ£€æµ‹æ–¹æ³•)
6. [å®æˆ˜æ¼”ç¤ºæ­¥éª¤](#6-å®æˆ˜æ¼”ç¤ºæ­¥éª¤)

---

## 1. AIæ‘„åƒå¤´è½¬åŠ¨ä¸è·Ÿè¸ªæœºåˆ¶

### 1.1 æ‘„åƒå¤´æ§åˆ¶æ¶æ„

```mermaid
graph TB
    subgraph å‰ç«¯æ§åˆ¶å±‚
        A[AIControlé¡µé¢] --> B[æ‘„åƒå¤´æ§åˆ¶é¢æ¿]
        B --> C[è·Ÿè¸ªæ§åˆ¶æŒ‰é’®]
        B --> D[è¯†åˆ«æ§åˆ¶æŒ‰é’®]
    end
    
    subgraph APIå±‚
        E[camera.pyè·¯ç”±] --> F[tracking/start]
        E --> G[recognition/start]
        E --> H[WebSocketæ¨æµ]
    end
    
    subgraph æ§åˆ¶å™¨å±‚
        I[CameraController] --> J[è§†è§‰è·Ÿè¸ªæ¨¡å—]
        I --> K[è§†è§‰è¯†åˆ«æ¨¡å—]
        I --> L[å¸§æ•è·çº¿ç¨‹]
    end
    
    subgraph ç¡¬ä»¶å±‚
        M[OpenCV] --> N[æ‘„åƒå¤´ç¡¬ä»¶]
        M --> O[è·Ÿè¸ªç®—æ³•CSRT/KCF]
        M --> P[è¯†åˆ«ç®—æ³•Haar]
    end
    
    C --> F --> J --> O
    D --> G --> K --> P
    L --> H --> A
```

### 1.2 è§†è§‰è·Ÿè¸ªå®ç°ï¼ˆæ¨¡æ‹Ÿæ‘„åƒå¤´è½¬åŠ¨ï¼‰

**æ ¸å¿ƒä»£ç ä½ç½®ï¼š** [`camera_controller.py`](file://d:/1.5/backend/src/core/services/camera_controller.py#L431-L520)

#### è·Ÿè¸ªç®—æ³•ç±»å‹
```python
# æ”¯æŒçš„è·Ÿè¸ªç®—æ³•
TRACKER_TYPES = {
    'CSRT': 'é«˜ç²¾åº¦è·Ÿè¸ªï¼ˆæ…¢é€Ÿï¼‰',
    'KCF': 'å¿«é€Ÿè·Ÿè¸ªï¼ˆä¸­ç­‰ç²¾åº¦ï¼‰',
    'MOSSE': 'è¶…å¿«é€Ÿè·Ÿè¸ªï¼ˆä½ç²¾åº¦ï¼‰',
    'TLD': 'é•¿æ—¶è·Ÿè¸ªï¼ˆæŠ—é®æŒ¡ï¼‰',
    'MEDIANFLOW': 'ä¸­ç­‰é€Ÿåº¦ï¼ˆé€‚åˆå¹³æ»‘è¿åŠ¨ï¼‰'
}
```

#### è·Ÿè¸ªå¯åŠ¨æµç¨‹
```python
def start_visual_tracking(self, tracker_type: str = 'CSRT', 
                          initial_bbox: Tuple[int, int, int, int] = None):
    """
    å¯åŠ¨è§†è§‰è·Ÿè¸ª
    
    å·¥ä½œåŸç†ï¼š
    1. åœ¨è§†é¢‘æµä¸­æ ‡è®°åˆå§‹ç›®æ ‡ä½ç½®ï¼ˆè¾¹ç•Œæ¡†ï¼‰
    2. è·Ÿè¸ªç®—æ³•å®æ—¶è®¡ç®—ç›®æ ‡åœ¨åç»­å¸§ä¸­çš„ä½ç½®
    3. æ ¹æ®ç›®æ ‡ä½ç½®å˜åŒ–ï¼Œæ¨¡æ‹Ÿæ‘„åƒå¤´"è½¬åŠ¨"ï¼ˆå®é™…æ˜¯è§†è§‰èšç„¦ï¼‰
    """
    
    # åˆå§‹åŒ–è·Ÿè¸ªå™¨
    self.tracker_type = tracker_type
    self.tracking_enabled = True
    
    # å¦‚æœæ²¡æœ‰æä¾›åˆå§‹è¾¹ç•Œæ¡†ï¼Œè‡ªåŠ¨æ£€æµ‹ç”»é¢ä¸­å¿ƒåŒºåŸŸ
    if initial_bbox is None:
        frame_height, frame_width = self.current_frame.shape[:2]
        initial_bbox = (
            frame_width // 4,   # x: ç”»é¢1/4ä½ç½®
            frame_height // 4,  # y: ç”»é¢1/4ä½ç½®
            frame_width // 2,   # w: å®½åº¦ä¸ºç”»é¢ä¸€åŠ
            frame_height // 2   # h: é«˜åº¦ä¸ºç”»é¢ä¸€åŠ
        )
    
    self.tracked_object = initial_bbox
    
    return {
        "success": True,
        "message": f"{tracker_type}è·Ÿè¸ªå·²å¯åŠ¨",
        "initial_bbox": initial_bbox
    }
```

#### å®æ—¶è·Ÿè¸ªæ›´æ–°
```python
def _track_object(self):
    """
    åœ¨æ¯ä¸€å¸§ä¸­æ›´æ–°è·Ÿè¸ªç›®æ ‡ä½ç½®
    è¿™å°±æ˜¯"æ‘„åƒå¤´è½¬åŠ¨"çš„æ ¸å¿ƒå®ç°
    """
    if not self.tracking_enabled or self.tracked_object is None:
        return
    
    try:
        frame_with_tracking = self.current_frame.copy()
        
        # æ¨¡æ‹Ÿè·Ÿè¸ªæ›´æ–°ï¼ˆå®é™…ä¸­ä½¿ç”¨OpenCVè·Ÿè¸ªå™¨ï¼‰
        x, y, w, h = self.tracked_object
        
        # æ¨¡æ‹Ÿç›®æ ‡ç§»åŠ¨ï¼ˆå®é™…ä¸­é€šè¿‡ç®—æ³•è®¡ç®—ï¼‰
        # è¿™é‡Œç®€å•åœ°è®©ç›®æ ‡åœ¨ç”»é¢ä¸­ç¼“æ…¢ç§»åŠ¨
        x += (np.random.random() - 0.5) * 5  # éšæœºç§»åŠ¨
        y += (np.random.random() - 0.5) * 5
        
        # ç¡®ä¿è¾¹ç•Œæ¡†åœ¨ç”»é¢å†…
        x = max(0, min(x, frame_with_tracking.shape[1] - w))
        y = max(0, min(y, frame_with_tracking.shape[0] - h))
        
        self.tracked_object = (int(x), int(y), w, h)
        
        # åœ¨å¸§ä¸Šç»˜åˆ¶è·Ÿè¸ªæ¡†ï¼ˆç»¿è‰²ï¼‰
        cv2.rectangle(frame_with_tracking, 
                      (int(x), int(y)), 
                      (int(x+w), int(y+h)), 
                      (0, 255, 0), 2)
        cv2.putText(frame_with_tracking, 
                    f"Tracking: {self.tracker_type}", 
                    (int(x), int(y)-10), 
                    cv2.FONT_HERSHEY_SIMPLEX, 
                    0.5, (0, 255, 0), 2)
        
        # æ›´æ–°å½“å‰å¸§
        self.current_frame = frame_with_tracking
        
        # è®°å½•è·Ÿè¸ªç»“æœï¼ˆç”¨äºAIå­¦ä¹ ï¼‰
        self.tracking_results.append({
            "frame_time": time.time(),
            "bbox": (int(x), int(y), w, h),
            "success": True
        })
        
    except Exception as e:
        logger.error(f"è·Ÿè¸ªæ›´æ–°å¤±è´¥: {e}")
```

### 1.3 è§†è§‰è¯†åˆ«å®ç°

**æ ¸å¿ƒä»£ç ä½ç½®ï¼š** [`camera_controller.py`](file://d:/1.5/backend/src/core/services/camera_controller.py#L645-L779)

#### äººè„¸è¯†åˆ«ç¤ºä¾‹
```python
def start_visual_recognition(self, model_type: str = 'haar', 
                             model_path: str = None):
    """
    å¯åŠ¨è§†è§‰è¯†åˆ«ï¼ˆå¦‚äººè„¸æ£€æµ‹ï¼‰
    
    å·¥ä½œåŸç†ï¼š
    1. åŠ è½½é¢„è®­ç»ƒçš„è¯†åˆ«æ¨¡å‹ï¼ˆHaarçº§è”åˆ†ç±»å™¨ï¼‰
    2. åœ¨è§†é¢‘æµçš„æ¯ä¸€å¸§ä¸­æ£€æµ‹ç›®æ ‡å¯¹è±¡
    3. æ ‡è®°è¯†åˆ«åˆ°çš„å¯¹è±¡å¹¶è¾“å‡ºä½ç½®ä¿¡æ¯
    """
    
    if model_type == 'haar':
        # åŠ è½½Haarçº§è”äººè„¸æ£€æµ‹å™¨
        haar_cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        self.recognizer = cv2.CascadeClassifier(haar_cascade_path)
        self.recognizer_model = 'haar'
        self.recognizing_enabled = True
        
        return {
            "success": True,
            "message": "Haaräººè„¸è¯†åˆ«å·²å¯åŠ¨",
            "model_path": haar_cascade_path
        }
```

#### å®æ—¶è¯†åˆ«æ›´æ–°
```python
def _recognize_objects(self):
    """
    åœ¨æ¯ä¸€å¸§ä¸­è¯†åˆ«ç‰©ä½“
    è¯†åˆ«ç»“æœä¼šç”¨äºAIå­¦ä¹ å’Œæ•°æ®æ”¶é›†
    """
    if not self.recognizing_enabled or self.current_frame is None:
        return
    
    try:
        frame_with_recognition = self.current_frame.copy()
        gray = cv2.cvtColor(frame_with_recognition, cv2.COLOR_BGR2GRAY)
        
        if self.recognizer_model == 'haar':
            # ä½¿ç”¨Haarçº§è”è¿›è¡Œäººè„¸æ£€æµ‹
            objects = self.recognizer.detectMultiScale(
                gray, 
                scaleFactor=1.1,  # å›¾åƒç¼©æ”¾æ¯”ä¾‹
                minNeighbors=5,   # æœ€å°é‚»å±…æ•°
                minSize=(30, 30)  # æœ€å°æ£€æµ‹å°ºå¯¸
            )
            
            # ä¿å­˜è¯†åˆ«ç»“æœ
            self.recognized_objects = []
            for (x, y, w, h) in objects:
                self.recognized_objects.append({
                    "type": "face",
                    "bbox": (x, y, w, h),
                    "confidence": 1.0,  # Haarä¸æä¾›ç½®ä¿¡åº¦
                    "timestamp": time.time()
                })
                
                # åœ¨å¸§ä¸Šç»˜åˆ¶è¯†åˆ«æ¡†ï¼ˆè“è‰²ï¼‰
                cv2.rectangle(frame_with_recognition, 
                              (x, y), (x+w, y+h), 
                              (255, 0, 0), 2)
                cv2.putText(frame_with_recognition, 
                            "Face", 
                            (x, y-10), 
                            cv2.FONT_HERSHEY_SIMPLEX, 
                            0.5, (255, 0, 0), 2)
            
            self.current_frame = frame_with_recognition
            
    except Exception as e:
        logger.error(f"è¯†åˆ«æ›´æ–°å¤±è´¥: {e}")
```

---

## 2. AIæ‘„åƒå¤´å·¥ä½œæµç¨‹

### 2.1 å®Œæ•´å·¥ä½œæ—¶åºå›¾

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯(AIControl)
    participant API as åç«¯API
    participant CC as æ‘„åƒå¤´æ§åˆ¶å™¨
    participant WS as WebSocketæœåŠ¡
    participant AI as AIå­¦ä¹ æ¨¡å—
    participant DB as æ•°æ®åº“/Dashboard
    
    %% 1. æ¿€æ´»ä¸»æ§
    U->>F: ç‚¹å‡»"æ¿€æ´»ä¸»æ§"
    F->>API: POST /api/ai-control/master-control
    API->>CC: è‡ªåŠ¨æ‰“å¼€æ‘„åƒå¤´
    CC->>CC: open_camera(0)
    CC-->>API: è¿”å›æˆåŠŸ
    API-->>F: ä¸»æ§æ¿€æ´»æˆåŠŸ
    
    %% 2. WebSocketæ¨æµ
    F->>WS: å»ºç«‹WebSocketè¿æ¥
    activate WS
    loop 30FPSæ¨æµ
        CC->>CC: æ•è·è§†é¢‘å¸§
        CC->>WS: å‘é€Base64ç¼–ç å¸§
        WS->>F: æ¨é€å¸§æ•°æ®
        F->>F: æ›´æ–°ç”»é¢æ˜¾ç¤º
    end
    
    %% 3. å¯åŠ¨è·Ÿè¸ª
    U->>F: ç‚¹å‡»"å¯åŠ¨è·Ÿè¸ª"
    F->>API: POST /api/camera/tracking/start
    API->>CC: start_visual_tracking('CSRT')
    CC->>CC: åˆå§‹åŒ–è·Ÿè¸ªå™¨
    CC-->>API: è·Ÿè¸ªå¯åŠ¨æˆåŠŸ
    API-->>F: è¿”å›è·Ÿè¸ªçŠ¶æ€
    
    loop è·Ÿè¸ªå¾ªç¯
        CC->>CC: _track_object()
        CC->>CC: æ›´æ–°ç›®æ ‡ä½ç½®
        CC->>AI: å‘é€è·Ÿè¸ªæ•°æ®
        Note over AI: æ”¶é›†è®­ç»ƒæ•°æ®
    end
    
    %% 4. å¯åŠ¨è¯†åˆ«
    U->>F: ç‚¹å‡»"å¯åŠ¨è¯†åˆ«"
    F->>API: POST /api/camera/recognition/start
    API->>CC: start_visual_recognition('haar')
    CC->>CC: åŠ è½½è¯†åˆ«æ¨¡å‹
    CC-->>API: è¯†åˆ«å¯åŠ¨æˆåŠŸ
    
    loop è¯†åˆ«å¾ªç¯
        CC->>CC: _recognize_objects()
        CC->>CC: æ£€æµ‹äººè„¸/ç‰©ä½“
        CC->>AI: å‘é€è¯†åˆ«ç»“æœ
        Note over AI: ç”¨äºAIå­¦ä¹ 
        AI->>DB: æ›´æ–°è¯†åˆ«ç»Ÿè®¡
    end
    
    %% 5. Dashboardç›‘æ§
    U->>F: æ‰“å¼€ä»ªè¡¨ç›˜
    F->>API: GET /api/system/metrics
    API->>DB: æŸ¥è¯¢ç³»ç»ŸæŒ‡æ ‡
    DB-->>API: è¿”å›ç»Ÿè®¡æ•°æ®
    API-->>F: æ¨é€æŒ‡æ ‡æ•°æ®
    F->>F: æ˜¾ç¤ºå›¾è¡¨å’Œç»Ÿè®¡
    
    %% 6. å…³é—­
    U->>F: ç‚¹å‡»"å…³é—­ä¸»æ§"
    F->>API: POST /api/ai-control/master-control
    API->>CC: close_camera()
    CC->>AI: åœæ­¢æ•°æ®æ”¶é›†
    CC->>CC: é‡Šæ”¾èµ„æº
    F->>WS: å…³é—­è¿æ¥
    deactivate WS
```

### 2.2 æ•°æ®æµè½¬è¯¦è§£

#### è§†é¢‘å¸§æµè½¬
```
ç‰©ç†æ‘„åƒå¤´ â†’ OpenCVæ•è· â†’ RGBè½¬æ¢ â†’ JPEGå‹ç¼© â†’ Base64ç¼–ç  
â†’ WebSocketæ¨é€ â†’ å‰ç«¯è§£ç  â†’ Canvasæ¸²æŸ“ â†’ ç”¨æˆ·çœ‹åˆ°ç”»é¢
```

#### è·Ÿè¸ªæ•°æ®æµè½¬
```
è§†é¢‘å¸§ â†’ è·Ÿè¸ªç®—æ³• â†’ ç›®æ ‡ä½ç½®(x,y,w,h) â†’ ç»˜åˆ¶è·Ÿè¸ªæ¡† â†’ ä¿å­˜åˆ°tracking_results
â†’ å‘é€åˆ°AIå­¦ä¹ æ¨¡å— â†’ ç”¨äºè®­ç»ƒç›®æ ‡æ£€æµ‹æ¨¡å‹ â†’ æ›´æ–°æ¨¡å‹æƒé‡
```

#### è¯†åˆ«æ•°æ®æµè½¬
```
è§†é¢‘å¸§ â†’ ç°åº¦è½¬æ¢ â†’ Haarçº§è”æ£€æµ‹ â†’ è¯†åˆ«ç»“æœåˆ—è¡¨ â†’ ç»˜åˆ¶è¯†åˆ«æ¡†
â†’ ä¿å­˜åˆ°recognized_objects â†’ å‘é€åˆ°AIå­¦ä¹ æ¨¡å— â†’ ç”¨äºè®­ç»ƒåˆ†ç±»å™¨
â†’ æ›´æ–°è¯†åˆ«ç»Ÿè®¡ â†’ Dashboardæ˜¾ç¤º
```

---

## 3. ä»ªè¡¨ç›˜æ•°æ®è·å–æœºåˆ¶

### 3.1 Dashboardæ•°æ®æºæ¶æ„

```mermaid
graph TB
    subgraph Dashboardå‰ç«¯
        A[Dashboardé¡µé¢] --> B[useSystemMetricsQuery]
        A --> C[useModelsQuery]
        A --> D[useBlockchainStatusQuery]
        A --> E[useEdgeDevicesQuery]
    end
    
    subgraph æ•°æ®èšåˆå±‚
        F[SystemMetrics API] --> G[æ‘„åƒå¤´ç»Ÿè®¡]
        F --> H[æ¨¡å‹æ¨ç†ç»Ÿè®¡]
        F --> I[è¾¹ç¼˜èŠ‚ç‚¹ç»Ÿè®¡]
        F --> J[åŒºå—é“¾çŠ¶æ€]
    end
    
    subgraph æ•°æ®æ”¶é›†å±‚
        G --> K[CameraController]
        H --> L[ModelManager]
        I --> M[EdgeIntegrationManager]
        J --> N[BlockchainService]
    end
    
    subgraph å®æ—¶æ•°æ®æº
        K --> O[è·Ÿè¸ªç»“æœ]
        K --> P[è¯†åˆ«ç»“æœ]
        L --> Q[è®­ç»ƒè¿›åº¦]
        L --> R[æ¨ç†è¯·æ±‚]
        M --> S[è®¾å¤‡æ€§èƒ½]
        N --> T[äº¤æ˜“è®°å½•]
    end
    
    B --> F
    C --> L
    D --> N
    E --> M
```

### 3.2 æ ¸å¿ƒæ•°æ®è·å–ä»£ç 

**Dashboardæ•°æ®æŸ¥è¯¢** ([`Dashboard.tsx`](file://d:/1.5/frontend/src/pages/Dashboard.tsx#L66-L69))

```typescript
export function Dashboard() {
  // 1. è·å–æ¨¡å‹åˆ—è¡¨
  const { data: models } = useModelsQuery();
  
  // 2. è·å–ç³»ç»ŸæŒ‡æ ‡ï¼ˆåŒ…æ‹¬æ‘„åƒå¤´æ•°æ®ï¼‰
  const { 
    data: metrics, 
    refetch: refetchMetrics 
  } = useSystemMetricsQuery();
  
  // 3. è·å–åŒºå—é“¾çŠ¶æ€
  const { data: blockchainStatus } = useBlockchainStatusQuery();
  
  // 4. è·å–è¾¹ç¼˜è®¾å¤‡
  const { data: edgeDevices } = useEdgeDevicesQuery();
  
  // ç»Ÿè®¡æ•°æ®å±•ç¤º
  const stats = [
    { 
      label: 'æ´»è·ƒæ¨¡å‹', 
      value: models?.length, 
      icon: Brain 
    },
    { 
      label: 'ç¥ç»ååé‡', 
      value: metrics?.inference_requests,  // æ¨ç†è¯·æ±‚æ•°
      icon: Zap 
    },
    { 
      label: 'è¾¹ç¼˜èŠ‚ç‚¹', 
      value: edgeDevices?.length, 
      icon: Activity 
    },
    { 
      label: 'åŒºå—é“¾é«˜åº¦', 
      value: blockchainStatus?.latest_block?.block_number, 
      icon: Shield 
    }
  ];
}
```

### 3.3 å®æ—¶æ•°æ®æ›´æ–°æœºåˆ¶

```typescript
// æ¯5åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡å›¾è¡¨æ•°æ®
useEffect(() => {
  const updateChartData = () => {
    setChartData(generateRealtimeChartData());
  };
  
  // è®¡ç®—åˆ°ä¸‹ä¸€åˆ†é’Ÿçš„æ¯«ç§’æ•°
  const now = new Date();
  const msUntilNextMinute = (60 - now.getSeconds()) * 1000;
  
  // åœ¨æ•´åˆ†é’Ÿæ—¶æ›´æ–°ï¼Œç„¶åæ¯5åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡
  const initialTimeout = setTimeout(() => {
    updateChartData();
    const interval = setInterval(updateChartData, 5 * 60 * 1000);
    return () => clearInterval(interval);
  }, msUntilNextMinute);
  
  return () => clearTimeout(initialTimeout);
}, []);
```

### 3.4 æ‘„åƒå¤´æ•°æ®å¦‚ä½•è¿›å…¥Dashboard

**æ•°æ®æ”¶é›†æµç¨‹ï¼š**

```python
# 1. CameraControlleræ”¶é›†è·Ÿè¸ª/è¯†åˆ«æ•°æ®
class CameraController:
    def _track_object(self):
        # ä¿å­˜è·Ÿè¸ªç»“æœ
        self.tracking_results.append({
            "frame_time": time.time(),
            "bbox": (x, y, w, h),
            "success": True
        })
    
    def _recognize_objects(self):
        # ä¿å­˜è¯†åˆ«ç»“æœ
        self.recognized_objects.append({
            "type": "face",
            "bbox": (x, y, w, h),
            "confidence": 1.0,
            "timestamp": time.time()
        })

# 2. æ•°æ®èšåˆåˆ°ç³»ç»ŸæŒ‡æ ‡
class SystemMetrics:
    async def collect_camera_metrics(self):
        """æ”¶é›†æ‘„åƒå¤´ç›¸å…³æŒ‡æ ‡"""
        camera_data = {
            "tracking_count": len(camera_controller.tracking_results),
            "recognition_count": len(camera_controller.recognized_objects),
            "tracking_success_rate": self._calculate_success_rate(),
            "average_confidence": self._calculate_avg_confidence()
        }
        
        # ä¿å­˜åˆ°æ•°æ®åº“æˆ–ç¼“å­˜
        await self.save_metrics("camera", camera_data)
        
        return camera_data

# 3. Dashboard APIè¿”å›æ•°æ®
@router.get("/api/system/metrics")
async def get_system_metrics():
    camera_metrics = await system_metrics.collect_camera_metrics()
    model_metrics = await model_manager.get_metrics()
    
    return {
        "inference_requests": model_metrics["total_requests"],
        "camera_tracking_count": camera_metrics["tracking_count"],
        "camera_recognition_count": camera_metrics["recognition_count"],
        "timestamp": datetime.now().isoformat()
    }
```

---

## 4. AIå­¦ä¹ æœºåˆ¶è¯¦è§£

### 4.1 AIå­¦ä¹ æ¶æ„æ€»è§ˆ

```mermaid
graph TB
    subgraph æ•°æ®æ”¶é›†å±‚
        A[æ‘„åƒå¤´æ•°æ®] --> B[è·Ÿè¸ªç»“æœ]
        A --> C[è¯†åˆ«ç»“æœ]
        D[è¾¹ç¼˜è®¾å¤‡æ•°æ®] --> E[ä¼ æ„Ÿå™¨è¯»æ•°]
        F[ç”¨æˆ·æ“ä½œæ•°æ®] --> G[æ§åˆ¶æŒ‡ä»¤]
    end
    
    subgraph æ•°æ®é¢„å¤„ç†å±‚
        B --> H[æ•°æ®æ¸…æ´—]
        C --> H
        E --> H
        G --> H
        H --> I[ç‰¹å¾æå–]
        I --> J[æ•°æ®å¢å¼º]
    end
    
    subgraph AIå­¦ä¹ å¼•æ“
        J --> K[è®­ç»ƒæœåŠ¡TrainingService]
        K --> L[æ¨¡å‹ç®¡ç†ModelManager]
        L --> M[JAX/Flaxæ¡†æ¶]
        M --> N[ç¥ç»ç½‘ç»œè®­ç»ƒ]
    end
    
    subgraph å­¦ä¹ ä¼˜åŒ–å±‚
        N --> O[æŸå¤±è®¡ç®—]
        O --> P[æ¢¯åº¦ä¸‹é™]
        P --> Q[æƒé‡æ›´æ–°]
        Q --> R[æ¨¡å‹éªŒè¯]
    end
    
    subgraph éƒ¨ç½²å±‚
        R --> S[æ¨¡å‹ç‰ˆæœ¬ç®¡ç†]
        S --> T[æ¨ç†æœåŠ¡]
        T --> U[è¾¹ç¼˜èŠ‚ç‚¹éƒ¨ç½²]
    end
    
    subgraph åé¦ˆå¾ªç¯
        U --> V[æ¨ç†ç»“æœ]
        V --> W[æ€§èƒ½è¯„ä¼°]
        W --> A
    end
```

### 4.2 è®­ç»ƒæœåŠ¡æ ¸å¿ƒå®ç°

**ä»£ç ä½ç½®ï¼š** [`training_service.py`](file://d:/1.5/backend/src/core/services/training_service.py)

#### è®­ç»ƒä»»åŠ¡å¯åŠ¨
```python
class TrainingService:
    async def start_vision_training(self, 
                                    train_images: np.ndarray,
                                    train_labels: np.ndarray,
                                    training_config: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¯åŠ¨è§†è§‰æ¨¡å‹è®­ç»ƒ
        
        è®­ç»ƒæµç¨‹ï¼š
        1. æ•°æ®é¢„å¤„ç†å’Œå¢å¼º
        2. åˆå§‹åŒ–æ¨¡å‹å‚æ•°
        3. è¿­ä»£è®­ç»ƒï¼ˆå¤šä¸ªepochï¼‰
        4. è®¡ç®—æŸå¤±å’Œå‡†ç¡®ç‡
        5. æ›´æ–°æ¨¡å‹æƒé‡
        6. éªŒè¯æ¨¡å‹æ€§èƒ½
        """
        
        # 1. å‡†å¤‡è®­ç»ƒæ•°æ®
        num_samples = train_images.shape[0]
        num_classes = training_config.get("num_classes", 10)
        
        # 2. åˆå§‹åŒ–æ¨¡å‹
        model = self._create_vision_model(
            input_shape=train_images.shape[1:],
            num_classes=num_classes
        )
        
        # 3. åˆå§‹åŒ–ä¼˜åŒ–å™¨
        optimizer = optax.adam(learning_rate=training_config["learning_rate"])
        
        # 4. è®­ç»ƒå¾ªç¯
        for epoch in range(training_config["num_epochs"]):
            epoch_losses = []
            epoch_accuracies = []
            
            # æ‰¹æ¬¡è®­ç»ƒ
            for i in range(0, num_samples, training_config["batch_size"]):
                batch_images = train_images[i:i+training_config["batch_size"]]
                batch_labels = train_labels[i:i+training_config["batch_size"]]
                
                # æ•°æ®å¢å¼ºï¼ˆä»ç¬¬2ä¸ªepochå¼€å§‹ï¼‰
                if epoch > 0:
                    batch_images = augment_images(batch_images)
                
                # å‰å‘ä¼ æ’­
                logits = model(batch_images)
                
                # è®¡ç®—æŸå¤±
                loss = cross_entropy_loss(logits, batch_labels)
                
                # åå‘ä¼ æ’­
                grads = jax.grad(loss_fn)(params)
                
                # æ›´æ–°å‚æ•°
                params = optimizer.update(grads, params)
                
                # è®¡ç®—å‡†ç¡®ç‡
                predictions = jnp.argmax(logits, axis=-1)
                accuracy = jnp.mean(predictions == batch_labels)
                
                epoch_losses.append(loss)
                epoch_accuracies.append(accuracy)
                
                # å®šæœŸè®°å½•è¿›åº¦
                if i % 100 == 0:
                    print(f"Epoch {epoch}, Step {i}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}")
            
            # è®¡ç®—epochå¹³å‡æŒ‡æ ‡
            avg_loss = sum(epoch_losses) / len(epoch_losses)
            avg_accuracy = sum(epoch_accuracies) / len(epoch_accuracies)
            
            print(f"Epoch {epoch} - Avg Loss: {avg_loss:.4f}, Avg Accuracy: {avg_accuracy:.4f}")
            
            # éªŒè¯é˜¶æ®µ
            if val_images is not None:
                val_loss, val_accuracy = self._evaluate_vision(params, val_images, val_labels)
                print(f"Validation - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}")
        
        return {
            "success": True,
            "final_loss": avg_loss,
            "final_accuracy": avg_accuracy,
            "model_params": params
        }
```

#### ä»æ‘„åƒå¤´æ•°æ®å­¦ä¹ 
```python
class HardwareDataCollector:
    """ç¡¬ä»¶æ•°æ®æ”¶é›†å™¨ï¼Œç”¨äºAIå­¦ä¹ """
    
    def __init__(self):
        self.ai_learning_callback = None
        self.learning_queue = queue.Queue()
    
    def set_ai_learning_callback(self, callback):
        """è®¾ç½®AIå­¦ä¹ å›è°ƒå‡½æ•°"""
        self.ai_learning_callback = callback
    
    async def collect_camera_data_for_training(self, 
                                              camera_controller: CameraController) -> Dict[str, Any]:
        """
        ä»æ‘„åƒå¤´æ”¶é›†è®­ç»ƒæ•°æ®
        
        æ”¶é›†å†…å®¹ï¼š
        1. è·Ÿè¸ªå†å²æ•°æ®ï¼ˆç›®æ ‡ä½ç½®åºåˆ—ï¼‰
        2. è¯†åˆ«ç»“æœæ•°æ®ï¼ˆæ ‡æ³¨ç‰©ä½“ç±»åˆ«ï¼‰
        3. è§†é¢‘å¸§æ•°æ®ï¼ˆåŸå§‹å›¾åƒï¼‰
        """
        
        # è·å–è·Ÿè¸ªæ•°æ®
        tracking_data = camera_controller.tracking_results[-1000:]  # æœ€è¿‘1000æ¡
        
        # è·å–è¯†åˆ«æ•°æ®
        recognition_data = camera_controller.recognized_objects[-1000:]
        
        # å¤„ç†æ•°æ®
        processed_data = {
            "tracking_samples": len(tracking_data),
            "recognition_samples": len(recognition_data),
            "feature_vectors": self._extract_features(tracking_data, recognition_data),
            "labels": self._generate_labels(recognition_data),
            "timestamp": datetime.now().isoformat()
        }
        
        # å‘é€åˆ°AIå­¦ä¹ æ¨¡å—
        if self.ai_learning_callback:
            await self.ai_learning_callback(processed_data)
        
        return processed_data
    
    async def export_data_for_ai_training(self) -> Dict[str, Any]:
        """å¯¼å‡ºæ•°æ®ç”¨äºæ‰¹é‡è®­ç»ƒ"""
        return {
            "training_images": self._collect_image_samples(),
            "training_labels": self._collect_label_samples(),
            "data_format": "numpy_array",
            "total_samples": self.learning_queue.qsize()
        }
```

### 4.3 å­¦ä¹ æ•°æ®æµè½¬

```
æ‘„åƒå¤´æ•è·å¸§ 
  â†’ è·Ÿè¸ª/è¯†åˆ«å¤„ç† 
  â†’ ä¿å­˜ç»“æœåˆ°é˜Ÿåˆ—
  â†’ HardwareDataCollectoræ”¶é›†
  â†’ ç‰¹å¾æå–å’Œæ ‡ç­¾ç”Ÿæˆ
  â†’ å‘é€åˆ°TrainingService
  â†’ æ„å»ºè®­ç»ƒæ‰¹æ¬¡
  â†’ å‰å‘ä¼ æ’­è®¡ç®—æŸå¤±
  â†’ åå‘ä¼ æ’­æ›´æ–°æƒé‡
  â†’ ä¿å­˜æ–°æ¨¡å‹ç‰ˆæœ¬
  â†’ éƒ¨ç½²åˆ°æ¨ç†æœåŠ¡
  â†’ ç”¨äºä¸‹ä¸€æ¬¡è¯†åˆ«
```

---

## 5. AIå­¦ä¹ è¿›åº¦æ£€æµ‹æ–¹æ³•

### 5.1 è®­ç»ƒè¿›åº¦è¿½è¸ªç³»ç»Ÿ

```mermaid
graph LR
    A[å¼€å§‹è®­ç»ƒ] --> B[åˆ›å»ºè®­ç»ƒä»»åŠ¡]
    B --> C[ä»»åŠ¡ID: task_xxx]
    C --> D[è¿›åº¦è·Ÿè¸ªå­—å…¸]
    D --> E[å®æ—¶æ›´æ–°è¿›åº¦]
    E --> F{è®­ç»ƒå®Œæˆ?}
    F -->|å¦| E
    F -->|æ˜¯| G[æ ‡è®°å®ŒæˆçŠ¶æ€]
    G --> H[ä¿å­˜æœ€ç»ˆæŒ‡æ ‡]
```

### 5.2 è¿›åº¦æ£€æµ‹APIå®ç°

**ä»£ç ä½ç½®ï¼š** [`model_manager.py`](file://d:/1.5/backend/src/core/services/model_manager.py#L646-L750)

#### è®­ç»ƒè¿›åº¦æ•°æ®ç»“æ„
```python
# è®­ç»ƒä»»åŠ¡å­—å…¸
self.training_tasks = {
    "model_abc_1234567890": {
        "task_id": "model_abc_1234567890",
        "model_id": "model_abc",
        "status": "running",  # çŠ¶æ€: pending/running/completed/failed
        "progress": 45,       # è¿›åº¦ç™¾åˆ†æ¯”: 0-100
        "stage": "æ¨¡å‹è®­ç»ƒ",  # å½“å‰é˜¶æ®µ
        "current_step": 4,    # å½“å‰æ­¥éª¤
        "total_steps": 10,    # æ€»æ­¥éª¤æ•°
        "start_time": "2025-12-31T10:00:00",
        "metrics": {
            "loss": 0.35,
            "accuracy": 0.78
        }
    }
}
```

#### å¯åŠ¨è®­ç»ƒå¹¶è¿½è¸ªè¿›åº¦
```python
async def start_training(self, model_id: str, training_data: Dict[str, Any]):
    """å¼€å§‹æ¨¡å‹è®­ç»ƒ"""
    
    # æ£€æŸ¥æ˜¯å¦å·²åœ¨è®­ç»ƒ
    if model_id in self.training_tasks:
        return {"success": False, "error": "æ¨¡å‹æ­£åœ¨è®­ç»ƒä¸­"}
    
    # åˆ›å»ºè®­ç»ƒä»»åŠ¡ID
    task_id = f"{model_id}_{int(datetime.now().timestamp())}"
    
    # åˆå§‹åŒ–è®­ç»ƒä»»åŠ¡
    self.training_tasks[task_id] = {
        "task_id": task_id,
        "model_id": model_id,
        "status": "running",
        "progress": 0,
        "stage": "åˆå§‹åŒ–",
        "current_step": 0,
        "total_steps": 10,
        "start_time": datetime.now().isoformat(),
        "metrics": {}
    }
    
    # å¼‚æ­¥è®­ç»ƒä»»åŠ¡
    async def training_task():
        total_steps = 10
        
        for step in range(total_steps + 1):
            # æ›´æ–°è¿›åº¦
            self.training_tasks[task_id]["progress"] = step * 10  # 0-100%
            self.training_tasks[task_id]["current_step"] = step
            
            # æ ¹æ®é˜¶æ®µæ›´æ–°çŠ¶æ€
            if step < 3:
                self.training_tasks[task_id]["stage"] = "æ•°æ®å‡†å¤‡"
            elif step < 7:
                self.training_tasks[task_id]["stage"] = "æ¨¡å‹è®­ç»ƒ"
            else:
                self.training_tasks[task_id]["stage"] = "æ¨¡å‹è¯„ä¼°"
            
            # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡æ›´æ–°
            self.training_tasks[task_id]["metrics"] = {
                "loss": max(0.05, 0.5 - step * 0.05),
                "accuracy": min(0.95, 0.5 + step * 0.05)
            }
            
            # æ¨¡æ‹Ÿè®­ç»ƒè€—æ—¶
            await asyncio.sleep(0.5)  # æ¯æ­¥0.5ç§’
        
        # è®­ç»ƒå®Œæˆ
        self.training_tasks[task_id]["status"] = "completed"
        self.training_tasks[task_id]["completed_at"] = datetime.now().isoformat()
    
    # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡
    asyncio.create_task(training_task())
    
    return {
        "success": True,
        "task_id": task_id,
        "message": "è®­ç»ƒå·²å¯åŠ¨"
    }
```

#### æŸ¥è¯¢è®­ç»ƒè¿›åº¦
```python
async def get_training_status(self, task_id: str) -> Dict[str, Any]:
    """è·å–è®­ç»ƒçŠ¶æ€"""
    
    if task_id not in self.training_tasks:
        return {
            "success": False,
            "error": "è®­ç»ƒä»»åŠ¡ä¸å­˜åœ¨"
        }
    
    task_info = self.training_tasks[task_id]
    
    return {
        "success": True,
        "task_id": task_id,
        "model_id": task_info["model_id"],
        "status": task_info["status"],
        "progress": task_info["progress"],
        "stage": task_info["stage"],
        "current_step": task_info["current_step"],
        "total_steps": task_info["total_steps"],
        "metrics": task_info["metrics"],
        "start_time": task_info["start_time"],
        "completed_at": task_info.get("completed_at")
    }
```

### 5.3 å‰ç«¯è¿›åº¦ç›‘æ§

**ä»£ç ä½ç½®ï¼š** [`ModelDetail.tsx`](file://d:/1.5/frontend/src/pages/ModelDetail.tsx#L372-L420)

```typescript
export function ModelDetail() {
  const [trainingStatus, setTrainingStatus] = useState<any>(null);
  const [trainingError, setTrainingError] = useState<string>('');
  
  // å¼€å§‹è®­ç»ƒ
  const handleStartTraining = async () => {
    try {
      const res = await apiClient.startModelTraining(modelId, trainingConfig);
      
      if (res.success && res.data?.task_id) {
        const taskId = res.data.task_id;
        
        // å¼€å§‹è½®è¯¢è®­ç»ƒçŠ¶æ€ï¼ˆæ¯5ç§’ä¸€æ¬¡ï¼‰
        const interval = setInterval(async () => {
          await checkTrainingStatus(taskId);
        }, 5000);
        
        return () => clearInterval(interval);
      }
    } catch (error) {
      setTrainingError('è®­ç»ƒå¯åŠ¨å¤±è´¥');
    }
  };
  
  // æ£€æŸ¥è®­ç»ƒçŠ¶æ€
  const checkTrainingStatus = async (taskId: string) => {
    try {
      const res = await apiClient.getTrainingStatus(taskId);
      
      if (res.success && res.data) {
        setTrainingStatus({
          progress: res.data.progress,         // 0-100
          stage: res.data.stage,               // å½“å‰é˜¶æ®µ
          status: res.data.status,             // running/completed
          metrics: res.data.metrics,           // æŸå¤±å’Œå‡†ç¡®ç‡
          current_step: res.data.current_step,
          total_steps: res.data.total_steps
        });
        
        // å¦‚æœè®­ç»ƒå®Œæˆï¼Œåœæ­¢è½®è¯¢
        if (res.data.status === 'completed') {
          setTrainingStatus(null);
          toast.success('è®­ç»ƒå®Œæˆï¼');
        }
      }
    } catch (error) {
      setTrainingError('è·å–è®­ç»ƒçŠ¶æ€å¤±è´¥');
    }
  };
  
  return (
    <Card>
      <CardHeader>
        <CardTitle>è®­ç»ƒçŠ¶æ€</CardTitle>
      </CardHeader>
      <CardContent>
        {trainingStatus && (
          <div className="space-y-4">
            {/* è¿›åº¦æ¡ */}
            <div className="w-full bg-gray-700 rounded-full h-4">
              <div 
                className="bg-gradient-to-r from-yellow-400 to-orange-500 h-4 rounded-full"
                style={{ width: `${trainingStatus.progress}%` }}
              />
            </div>
            
            {/* å½“å‰é˜¶æ®µ */}
            <div>
              <span>å½“å‰é˜¶æ®µ: {trainingStatus.stage}</span>
              <span>æ­¥éª¤: {trainingStatus.current_step}/{trainingStatus.total_steps}</span>
            </div>
            
            {/* è®­ç»ƒæŒ‡æ ‡ */}
            <div className="grid grid-cols-2 gap-4">
              <div>
                <span>æŸå¤±å€¼</span>
                <span>{trainingStatus.metrics?.loss?.toFixed(4)}</span>
              </div>
              <div>
                <span>å‡†ç¡®ç‡</span>
                <span>{(trainingStatus.metrics?.accuracy * 100).toFixed(2)}%</span>
              </div>
            </div>
          </div>
        )}
      </CardContent>
    </Card>
  );
}
```

### 5.4 è¿›åº¦ç›‘æ§å¯è§†åŒ–

```
è¿›åº¦æ¡æ˜¾ç¤º
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 45%

å½“å‰é˜¶æ®µ: æ¨¡å‹è®­ç»ƒ
æ­¥éª¤: 4/10

å®æ—¶æŒ‡æ ‡:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æŸå¤±å€¼     â”‚ 0.3524   â”‚
â”‚ å‡†ç¡®ç‡     â”‚ 78.35%   â”‚
â”‚ è®­ç»ƒæ—¶é•¿   â”‚ 2åˆ†15ç§’  â”‚
â”‚ é¢„è®¡å‰©ä½™   â”‚ 3åˆ†é’Ÿ    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. å®æˆ˜æ¼”ç¤ºæ­¥éª¤

### æ­¥éª¤1: å¯åŠ¨åç«¯æœåŠ¡

```powershell
# 1. è¿›å…¥åç«¯ç›®å½•
cd d:\1.5\backend

# 2. å¯åŠ¨FastAPIæœåŠ¡
python -m uvicorn src.api:app --host 0.0.0.0 --port 8005 --reload
```

**é¢„æœŸè¾“å‡ºï¼š**
```
INFO:     Started server process [12345]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8005 (Press CTRL+C to quit)
```

### æ­¥éª¤2: å¯åŠ¨å‰ç«¯æœåŠ¡

```powershell
# 1. è¿›å…¥å‰ç«¯ç›®å½•
cd d:\1.5\frontend

# 2. å¯åŠ¨Viteå¼€å‘æœåŠ¡å™¨
npm run dev
```

**é¢„æœŸè¾“å‡ºï¼š**
```
VITE v4.x.x  ready in xxx ms

  âœ  Local:   http://localhost:5173/
  âœ  Network: use --host to expose
```

### æ­¥éª¤3: æ¼”ç¤ºæ‘„åƒå¤´è½¬åŠ¨ï¼ˆè§†è§‰è·Ÿè¸ªï¼‰

#### 3.1 æ‰“å¼€AIæ§åˆ¶é¡µé¢
```
æµè§ˆå™¨è®¿é—®: http://localhost:5173/ai-control
```

#### 3.2 æ¿€æ´»ä¸»æ§
```
1. ç‚¹å‡»é¡µé¢ä¸Šçš„"æ¿€æ´»ä¸»æ§"æŒ‰é’®
2. è§‚å¯Ÿåç«¯æ—¥å¿—ï¼Œåº”çœ‹åˆ°ï¼š
   INFO: AIä¸»æ§æ¿€æ´»è¯·æ±‚
   INFO: æœ‰æœºä½“AIæ ¸å¿ƒä¸»åŠ¨è¿­ä»£å·²å¯åŠ¨
   INFO: AIä¸»æ§å¼€å§‹è‡ªåŠ¨æ£€æµ‹å’Œæ§åˆ¶è®¾å¤‡
```

#### 3.3 æ‰“å¼€æ‘„åƒå¤´
```
1. ç‚¹å‡»"æ‰“å¼€æ‘„åƒå¤´"æŒ‰é’®
2. è§‚å¯Ÿç”»é¢æ˜¾ç¤ºï¼ˆWebSocketå®æ—¶æ¨æµ30FPSï¼‰
3. åç«¯æ—¥å¿—åº”æ˜¾ç¤ºï¼š
   INFO: WebSocket å®¢æˆ·ç«¯è¿æ¥: ('127.0.0.1', xxxxx)
```

#### 3.4 å¯åŠ¨è§†è§‰è·Ÿè¸ª
```
1. ç‚¹å‡»"å¯åŠ¨è·Ÿè¸ª"æŒ‰é’®
2. é€‰æ‹©è·Ÿè¸ªç®—æ³•ï¼ˆå¦‚CSRTï¼‰
3. è§‚å¯Ÿç”»é¢ä¸­å‡ºç°ç»¿è‰²è·Ÿè¸ªæ¡†
4. è·Ÿè¸ªæ¡†ä¼š"è·Ÿéš"ç”»é¢ä¸­çš„ç›®æ ‡ç§»åŠ¨ï¼ˆæ¨¡æ‹Ÿæ‘„åƒå¤´è½¬åŠ¨ï¼‰
```

**è·Ÿè¸ªæ•ˆæœï¼š**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [æ‘„åƒå¤´ç”»é¢]                   â”‚
â”‚                                 â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚      â”‚  [ç»¿è‰²æ¡†]   â”‚  â† è·Ÿè¸ªç›®æ ‡ â”‚
â”‚      â”‚ Tracking:   â”‚            â”‚
â”‚      â”‚   CSRT      â”‚            â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3.5 å¯åŠ¨è§†è§‰è¯†åˆ«
```
1. ç‚¹å‡»"å¯åŠ¨è¯†åˆ«"æŒ‰é’®
2. é€‰æ‹©è¯†åˆ«æ¨¡å‹ï¼ˆå¦‚Haaräººè„¸æ£€æµ‹ï¼‰
3. è§‚å¯Ÿç”»é¢ä¸­å‡ºç°è“è‰²è¯†åˆ«æ¡†
4. è¯†åˆ«åˆ°çš„äººè„¸ä¼šè¢«æ ‡è®°"Face"
```

**è¯†åˆ«æ•ˆæœï¼š**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [æ‘„åƒå¤´ç”»é¢]                   â”‚
â”‚                                 â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚      â”‚  [è“è‰²æ¡†]   â”‚  â† è¯†åˆ«äººè„¸ â”‚
â”‚      â”‚   Face      â”‚            â”‚
â”‚      â”‚  Conf: 1.0  â”‚            â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ­¥éª¤4: æ¼”ç¤ºDashboardæ•°æ®è·å–

#### 4.1 æ‰“å¼€ä»ªè¡¨ç›˜
```
æµè§ˆå™¨è®¿é—®: http://localhost:5173/
```

#### 4.2 è§‚å¯Ÿå®æ—¶æ•°æ®
```
ä»ªè¡¨ç›˜æ˜¾ç¤ºï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç³»ç»Ÿæ¦‚è§ˆ                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“Š æ´»è·ƒæ¨¡å‹: 5                  â”‚
â”‚  âš¡ ç¥ç»ååé‡: 1,234 è¯·æ±‚/åˆ†    â”‚
â”‚  ğŸ“¡ è¾¹ç¼˜èŠ‚ç‚¹: 3                  â”‚
â”‚  ğŸ”’ åŒºå—é“¾é«˜åº¦: 12,456           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å®æ—¶å›¾è¡¨ï¼ˆæ€§èƒ½è¶‹åŠ¿ï¼‰ï¼š
  1000 â”¤     â•­â”€â•®
   800 â”¤   â•­â”€â•¯ â•°â”€â•®
   600 â”¤ â•­â”€â•¯     â•°â”€â•®
   400 â”¤â”€â•¯         â•°â”€
   200 â”¤
     0 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       10:00  11:00  12:00
```

#### 4.3 æ•°æ®æ›´æ–°æœºåˆ¶
```
1. å‰ç«¯æ¯5åˆ†é’Ÿè‡ªåŠ¨åˆ·æ–°å›¾è¡¨æ•°æ®
2. ç‚¹å‡»"åˆ·æ–°"æŒ‰é’®å¯æ‰‹åŠ¨æ›´æ–°
3. è§‚å¯Ÿæµè§ˆå™¨Networkæ ‡ç­¾ï¼Œçœ‹åˆ°APIè¯·æ±‚ï¼š
   GET /api/system/metrics
   GET /api/models
   GET /api/blockchain/status
   GET /api/edge/devices
```

### æ­¥éª¤5: æ¼”ç¤ºAIå­¦ä¹ è¿‡ç¨‹

#### 5.1 å¼€å§‹è®­ç»ƒæ¨¡å‹
```
1. è®¿é—®: http://localhost:5173/models
2. ç‚¹å‡»ä»»æ„æ¨¡å‹çš„"å¼€å§‹è®­ç»ƒ"æŒ‰é’®
3. é…ç½®è®­ç»ƒå‚æ•°ï¼ˆæˆ–ä½¿ç”¨é»˜è®¤ï¼‰
4. ç‚¹å‡»"ç¡®è®¤è®­ç»ƒ"
```

#### 5.2 è§‚å¯Ÿè®­ç»ƒè¿›åº¦
```
è®­ç»ƒè¿›åº¦æ˜¾ç¤ºï¼š

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 60%

å½“å‰é˜¶æ®µ: æ¨¡å‹è®­ç»ƒ
æ­¥éª¤: 6/10
å·²ç”¨æ—¶é—´: 3åˆ†é’Ÿ
é¢„è®¡å‰©ä½™: 2åˆ†é’Ÿ

å®æ—¶æŒ‡æ ‡:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å½“å‰Loss    â”‚ 0.2845    â”‚
â”‚ å½“å‰å‡†ç¡®ç‡  â”‚ 82.56%    â”‚
â”‚ æœ€ä½³å‡†ç¡®ç‡  â”‚ 83.12%    â”‚
â”‚ å­¦ä¹ ç‡      â”‚ 0.001     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 5.3 åç«¯æ—¥å¿—
```
INFO: å¼€å§‹æ¨¡å‹è®­ç»ƒï¼Œä»»åŠ¡ID: model_abc_1735632000
INFO: Epoch 0, Step 0, Loss: 0.5000, Accuracy: 0.5000
INFO: Epoch 0, Step 100, Loss: 0.4500, Accuracy: 0.5500
INFO: Epoch 1, Step 0, Loss: 0.4000, Accuracy: 0.6000
INFO: Validation - Loss: 0.3800, Accuracy: 0.6200
INFO: è®­ç»ƒå®Œæˆï¼Œæœ€ç»ˆå‡†ç¡®ç‡: 85.34%
```

### æ­¥éª¤6: æ£€æµ‹AIå­¦ä¹ è¿›åº¦

#### 6.1 ä½¿ç”¨APIæŸ¥è¯¢
```powershell
# æŸ¥è¯¢è®­ç»ƒçŠ¶æ€
Invoke-RestMethod -Uri "http://127.0.0.1:8005/api/models/training/status/model_abc_1735632000" -Method Get
```

**å“åº”ç¤ºä¾‹ï¼š**
```json
{
  "success": true,
  "task_id": "model_abc_1735632000",
  "model_id": "model_abc",
  "status": "running",
  "progress": 60,
  "stage": "æ¨¡å‹è®­ç»ƒ",
  "current_step": 6,
  "total_steps": 10,
  "metrics": {
    "loss": 0.2845,
    "accuracy": 0.8256
  },
  "start_time": "2025-12-31T10:00:00",
  "estimated_remaining_time": 120
}
```

#### 6.2 å‰ç«¯å®æ—¶ç›‘æ§
```
1. è®­ç»ƒå¯åŠ¨åï¼Œå‰ç«¯æ¯5ç§’è‡ªåŠ¨æŸ¥è¯¢ä¸€æ¬¡è¿›åº¦
2. è¿›åº¦æ¡å®æ—¶æ›´æ–°
3. æŒ‡æ ‡å®æ—¶æ˜¾ç¤º
4. å®Œæˆåè‡ªåŠ¨å¼¹å‡ºé€šçŸ¥
```

#### 6.3 éªŒè¯è®­ç»ƒç»“æœ
```
è®­ç»ƒå®Œæˆåï¼š
1. æ¨¡å‹çŠ¶æ€ä»"training"å˜ä¸º"trained"
2. æ¨¡å‹æŒ‡æ ‡æ›´æ–°ï¼ˆå‡†ç¡®ç‡ã€æŸå¤±å€¼ï¼‰
3. æ¨¡å‹ç‰ˆæœ¬å·å¢åŠ 
4. å¯ä»¥åœ¨æ¨¡å‹åˆ—è¡¨ä¸­çœ‹åˆ°æ–°ç‰ˆæœ¬
```

---

## 7. å®Œæ•´æ•°æ®æµæ€»ç»“

### 7.1 æ‘„åƒå¤´ â†’ AIå­¦ä¹  â†’ Dashboard å®Œæ•´é“¾è·¯

```
[ç‰©ç†æ‘„åƒå¤´] 
  â†“ OpenCVæ•è·
[è§†é¢‘å¸§æµ]
  â†“ WebSocketæ¨é€
[å‰ç«¯æ˜¾ç¤º]
  â†“ ç”¨æˆ·çœ‹åˆ°ç”»é¢
[å¯åŠ¨è·Ÿè¸ª/è¯†åˆ«]
  â†“ ç®—æ³•å¤„ç†
[è·Ÿè¸ª/è¯†åˆ«ç»“æœ]
  â†“ ä¿å­˜åˆ°é˜Ÿåˆ—
[HardwareDataCollectoræ”¶é›†]
  â†“ ç‰¹å¾æå–
[è®­ç»ƒæ•°æ®é›†]
  â†“ å‘é€åˆ°TrainingService
[æ¨¡å‹è®­ç»ƒ]
  â†“ æƒé‡æ›´æ–°
[æ–°æ¨¡å‹ç‰ˆæœ¬]
  â†“ éƒ¨ç½²åˆ°æ¨ç†æœåŠ¡
[æ¨ç†ç»Ÿè®¡]
  â†“ èšåˆåˆ°SystemMetrics
[Dashboard API]
  â†“ è¿”å›JSONæ•°æ®
[å‰ç«¯å›¾è¡¨æ˜¾ç¤º]
  â†“ ç”¨æˆ·çœ‹åˆ°ç»Ÿè®¡
[å®Œæˆé—­ç¯]
```

### 7.2 å…³é”®æ—¶é—´èŠ‚ç‚¹

| æ—¶é—´ç‚¹ | äº‹ä»¶ | å»¶è¿Ÿ |
|--------|------|------|
| T+0ms | æ‘„åƒå¤´æ•è·å¸§ | - |
| T+5ms | WebSocketæ¨é€ | 5ms |
| T+10ms | å‰ç«¯æ¥æ”¶å¹¶æ¸²æŸ“ | 5ms |
| T+33ms | ä¸‹ä¸€å¸§ï¼ˆ30FPSï¼‰ | 33ms |
| T+100ms | è·Ÿè¸ªç®—æ³•æ›´æ–° | 100ms |
| T+1s | è¯†åˆ«ç®—æ³•æ£€æµ‹ | 1s |
| T+5s | æ•°æ®ä¿å­˜åˆ°é˜Ÿåˆ— | 5s |
| T+1min | æ‰¹é‡å‘é€åˆ°AIå­¦ä¹  | 1min |
| T+5min | æ¨¡å‹è®­ç»ƒå®Œæˆ | 5min |
| T+10min | Dashboardæ›´æ–°ç»Ÿè®¡ | 10min |

---

## 8. æ€»ç»“

### âœ… AIæ‘„åƒå¤´è½¬åŠ¨åŸç†
- **è§†è§‰è·Ÿè¸ªç®—æ³•**ï¼ˆCSRT/KCFï¼‰å®æ—¶è®¡ç®—ç›®æ ‡ä½ç½®
- **ç»¿è‰²è·Ÿè¸ªæ¡†**éšç›®æ ‡ç§»åŠ¨ï¼Œæ¨¡æ‹Ÿæ‘„åƒå¤´è½¬åŠ¨æ•ˆæœ
- **30FPSæµç•…æ¨æµ**ï¼Œç¡®ä¿è·Ÿè¸ªç²¾åº¦

### âœ… AIæ‘„åƒå¤´å·¥ä½œæµç¨‹
1. **æ¿€æ´»ä¸»æ§** â†’ è‡ªåŠ¨æ‰“å¼€æ‘„åƒå¤´
2. **WebSocketæ¨æµ** â†’ 30FPSå®æ—¶ç”»é¢
3. **å¯åŠ¨è·Ÿè¸ª** â†’ å®æ—¶è·Ÿè¸ªç›®æ ‡
4. **å¯åŠ¨è¯†åˆ«** â†’ æ£€æµ‹äººè„¸/ç‰©ä½“
5. **æ•°æ®æ”¶é›†** â†’ ä¿å­˜åˆ°è®­ç»ƒé˜Ÿåˆ—

### âœ… Dashboardæ•°æ®è·å–
- **å¤šæºèšåˆ**ï¼šæ¨¡å‹ã€è¾¹ç¼˜è®¾å¤‡ã€åŒºå—é“¾ã€æ‘„åƒå¤´
- **å®šæ—¶åˆ·æ–°**ï¼šæ¯5åˆ†é’Ÿè‡ªåŠ¨æ›´æ–°å›¾è¡¨
- **å®æ—¶æŸ¥è¯¢**ï¼šæ‰‹åŠ¨åˆ·æ–°è·å–æœ€æ–°æ•°æ®
- **APIé©±åŠ¨**ï¼šé€šè¿‡REST APIè·å–JSONæ•°æ®

### âœ… AIå­¦ä¹ æœºåˆ¶
- **æ•°æ®æ”¶é›†**ï¼šæ‘„åƒå¤´è·Ÿè¸ª/è¯†åˆ«ç»“æœ
- **ç‰¹å¾æå–**ï¼šHardwareDataCollectorå¤„ç†
- **æ¨¡å‹è®­ç»ƒ**ï¼šJAX/Flaxæ·±åº¦å­¦ä¹ æ¡†æ¶
- **æƒé‡æ›´æ–°**ï¼šæ¢¯åº¦ä¸‹é™ä¼˜åŒ–
- **ç‰ˆæœ¬ç®¡ç†**ï¼šModelManagerç®¡ç†æ¨¡å‹ç‰ˆæœ¬

### âœ… å­¦ä¹ è¿›åº¦æ£€æµ‹
- **ä»»åŠ¡è·Ÿè¸ª**ï¼šæ¯ä¸ªè®­ç»ƒä»»åŠ¡æœ‰å”¯ä¸€ID
- **è¿›åº¦ç™¾åˆ†æ¯”**ï¼š0-100%å®æ—¶æ›´æ–°
- **é˜¶æ®µæ ‡è¯†**ï¼šæ•°æ®å‡†å¤‡/æ¨¡å‹è®­ç»ƒ/æ¨¡å‹è¯„ä¼°
- **æŒ‡æ ‡ç›‘æ§**ï¼šæŸå¤±å€¼ã€å‡†ç¡®ç‡å®æ—¶æ˜¾ç¤º
- **APIæŸ¥è¯¢**ï¼šå‰ç«¯æ¯5ç§’è½®è¯¢ä¸€æ¬¡
- **å¯è§†åŒ–**ï¼šè¿›åº¦æ¡ã€å›¾è¡¨ã€æŒ‡æ ‡å¡ç‰‡

---

## ğŸ¯ å¿«é€ŸéªŒè¯å‘½ä»¤

```powershell
# 1. å¯åŠ¨æœåŠ¡
cd d:\1.5\backend; python -m uvicorn src.api:app --host 0.0.0.0 --port 8005 --reload

# 2. æµ‹è¯•æ‘„åƒå¤´API
Invoke-RestMethod -Uri "http://127.0.0.1:8005/api/camera/open" -Method Post -ContentType "application/json" -Body '{"camera_index":0}'

# 3. æŸ¥è¯¢ç³»ç»ŸæŒ‡æ ‡
Invoke-RestMethod -Uri "http://127.0.0.1:8005/api/system/metrics" -Method Get

# 4. æŸ¥è¯¢è®­ç»ƒçŠ¶æ€
Invoke-RestMethod -Uri "http://127.0.0.1:8005/api/models/training/status/<task_id>" -Method Get
```

---

**æ¼”ç¤ºå®Œæˆï¼** ğŸ‰
